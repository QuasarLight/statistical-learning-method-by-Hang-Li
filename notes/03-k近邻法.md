# ${k}$ 近邻法

根据近邻来估计实例点的属性。有两种方式，一种是 ${Top-K}$ 最近邻，一种是根据距离确定近邻。前者算最近的 ${k}$ 个邻居，而后者计算离实例的距离在一定范围以内的所有邻居。分别适用于分布密集和分布稀疏的情况。

${KNN}$ 算法最大的问题在于计算 ${pair}$ 之间的距离，这是 ${(O(n^2))}$ 的问题，而每次增加点，都需要进行 ${N}$ 次计算，这是不可接受的，于是对实例存在的特征空间进行切分，具体算法即 ${kd}$ 树算法。按维度进行切分，思想类似于二分查找。

## ${k}$ 近邻算法

![简介](http://ofqm89vhw.bkt.clouddn.com/16bd39b6211de847c6f62e2bde0ab475.png)

### 距离度量

调整空间中两个实例点的距离是链各个实例点相似程度的反映。

![${L_p}$ 距离间的关系](http://ofqm89vhw.bkt.clouddn.com/c0ce977c1a970ae2a918450ce8579f02.png)

### ${k}$ 值的选择

### 分类决策规则

## ${k}$ 近邻法的实现：${kd}$ 树

### 构造 ${kd}$ 树

通常，一次选择坐标轴对空间切分，选择训练实例点在选定坐标轴上的中位数为切分点，这样得到的 ${kd}$ 树是平衡的。

### 搜索 ${kd}$ 树

给定一个目标点，搜索其最邻近。

## 本章概要

1. ${k}$ 近邻法是基本且简单的分类与回归方法。${k}$ 近邻法的基本做法是：对给定的训练实例点和输入实例点，首先确定输入实例点的 ${}$ 个最近邻训练实例点，然后利用这 ${}$ 个训练实例点的类的多数来预测输入实例点的类。
1. ${k}$ 近邻模型对应于基于训练
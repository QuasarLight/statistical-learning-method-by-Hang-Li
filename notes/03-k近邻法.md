# ${k}$ 近邻法

根据近邻来估计实例点的属性。有两种方式，一种是 ${Top-K}$ 最近邻，一种是根据距离确定近邻。前者算最近的 ${k}$ 个邻居，而后者计算离实例的距离在一定范围以内的所有邻居。分别适用于分布密集和分布稀疏的情况。

${KNN}$ 算法最大的问题在于计算 ${pair}$ 之间的距离，这是 ${(O(n^2))}$ 的问题，而每次增加点，都需要进行 ${N}$ 次计算，这是不可接受的，于是对实例存在的特征空间进行切分，具体算法即 ${kd}$ 树算法。按维度进行切分，思想类似于二分查找。

## ${k}$ 近邻算法

KNN（K-Nearest Neighbor）算法是机器学习中算法中最基础和简单的算法之一。它既能用于分类，也能用于回归。

KNN 算法的思想非常简单：对于任意的 ${n}$ 维输入向量，其对应于特征空间一个点，输出为该特征向量所对应的类别标签或者预测值。KNN 算法在机器学习算法中有一个十分特别的地方，那就是它没有一个显示的学习过程。它实际上的工作原理是利用训练数据对特征向量空间进行划分，并将其划分的结果作为其最终的算法模型。

![简介](http://ofqm89vhw.bkt.clouddn.com/16bd39b6211de847c6f62e2bde0ab475.png)

有两个因素必须确定才能使 KNN 分类算法真正能够运行：

1. 算法超参数 ${K}$。
2. 模型向量空间的距离度量。

### 距离度量

样本空间中两个点之间的距离度量表示的是两个样本点之间的相似程度：距离越短，表示相似程度越高；相反，距离越大，表示两个样本的相似程度低。

常用的距离度量方式有：

- 闵可夫斯基距离；
- 欧氏距离；
- 曼哈顿距离；
- 切比雪夫距离；
- 余弦距离。

![${L_p}$ 距离间的关系](http://ofqm89vhw.bkt.clouddn.com/c0ce977c1a970ae2a918450ce8579f02.png)

### ${k}$ 值的选择

KNN 算法中只有唯一的一个超参数 ${K}$，很明显 ${K}$ 值的选择对最终算法的预测结果会产生至关重要的影响。

如果 ${K}$ 值选择的比较小，这时候我们就相当于使用较小的领域中的训练样本对实例进行预测。这时候，算法的近似误差（Approximate Error）会减小，因为只有与输入实例相近的训练样本才能才会对预测结果起作用。但是它也会有明显的缺点：算法的估计误差会偏大，预测的结果会对近邻点十分敏感，也就是说如果近邻点是噪声点的话，那么预测就会出错。也就是说，${K}$ 值太小会使得 KNN 算法容易过拟合。

同理，如果 ${K}$ 值选的比较大的话，这时候距离较远的训练样本都能够对实例的预测结果产生影响。这时候，而模型相对比较鲁棒，不会因个别噪声点对最终的预测产生影响。但是缺点也是十分明显的：算法的近似误差会偏大，距离较远的点（与预测实例不相似）也会同样对预测结果产生作用，使得预测产生较大偏差。此时相当于模型发生欠拟合。

一般采用交叉验证的方式选取 ${K}$ 值，一般会选取 ${K}$ 值在较小的范围，同时在测试集上准确率最高的那一个确定为最终的算法超参数 ${K}$。

### 分类决策规则

## ${k}$ 近邻法的实现：${kd}$ 树

${KD}$-树 （K-dimension Tree）是一种对 ${K}$ 维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。 ${KD}$-树 是是一种二叉树，表示对 ${K}$ 维空间的一个划分，构造 ${KD}$-树 相当于不断地用垂直于坐标轴的超平面将 ${K}$ 维空间切分，构成一系列的 ${K}$ 维超矩形区域。${KD}$-树 的每个结点对应于一个 ${K}$ 维超矩形区域。利用 ${KD}$-树 可以省去对大部分数据点的搜索，从而减少搜索的计算量。

### 构造 ${kd}$ 树

通常，一次选择坐标轴对空间切分，选择训练实例点在选定坐标轴上的中位数为切分点，这样得到的 ${kd}$ 树是平衡的。

${KD}$-树 的构造是一个递归的方法：

1. 构造根节点，使根节点对应于 ${K}$ 维空间中包含的所有点的超矩形区域；
1. 不断地对 ${K}$ 维空间进行切分，生成子节点。

### 搜索 ${kd}$ 树

给定一个目标点，搜索其最邻近。

## KNN 回归算法

对新来的预测实例寻找 ${K}$ 近邻，然后对这 ${K}$ 个样本的目标值去均值即可作为新样本的预测值：

$${\hat{y} = \frac{1}{K} \sum_{i=1}^{K} y_i}$$

## 本章概要

1. ${k}$ 近邻法是基本且简单的分类与回归方法。${k}$ 近邻法的基本做法是：对给定的训练实例点和输入实例点，首先确定输入实例点的 ${}$ 个最近邻训练实例点，然后利用这 ${}$ 个训练实例点的类的多数来预测输入实例点的类。
1. ${k}$ 近邻模型对应于基于训练数据集对特征空间的一个划分。${k}$ 临近法中，当训练集、距离度量、${k}$ 值的选择和分类决策确定后，期结果唯一确定。
1. ${k}$ 临近法三要素：距离度量、${k}$ 值的选择和分类决策规则。。常用的距离度量是欧式距离及更一般的 ${L_p}$ 距离。${k}$ 值越小时，${k}$ 近邻模型更复杂；${k}$ 值越大时，
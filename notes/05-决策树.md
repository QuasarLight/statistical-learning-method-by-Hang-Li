# 决策树

决策树是一种基本的分类与回归方法，决策树呈树形结构，在分类问题找那个，表示基于特征对实例进行分类的过程。它可以认为是 if-then 规则的集合。也可以认为是定义在特征空间与类空间上的条件概率分布，主要优点是模型具有可读性，方便可视化，分类速度快，模型在学习的过程中，利用训练数据，根据损失函数最小化的原则建立决策树模型。预测时，对新的数据，利用决策树模型进行分类。决策树学习通常包括 ${3}$ 个步骤：特征选择，决策树的生成和决策树的修剪。

## 决策树模型与学习

### 决策树模型

![决策树对应特征空间划分和条件概率分布](http://ofqm89vhw.bkt.clouddn.com/15a2483c23c9f53b4f9a6de0541cd09e.png)

## 特征选择

### 特征选择问题

通常特征选择的准则是信息增益或者信息增益比。

理解为不断地提高所划分部分的纯度，即：使得各个子集在当前条件下有最好的分类，那么久应该选择这个特征。

### 信息增益

在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的度量。

![分布为贝努利分布时熵与概率的关系](http://ofqm89vhw.bkt.clouddn.com/7b5061af69f575ec2b06ff369b0e269c.png)

信息增益（information gain）表示得知特征 ${X}$ 的信息而使得类 ${Y}$ 的信息不确定性减少的程度。

$${g(D,A) = H(D) - H(D|A)}$$

## 决策树的生成

### ${ID3}$ 算法

### ${C4.5}$ 的生成算法

## 决策树的剪枝

## ${CART}$ 算法

### ${CART}$ 剪枝

## 本章概要

## 习题
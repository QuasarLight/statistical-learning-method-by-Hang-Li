# 统计学习方法概论

## 统计学习

`统计学习` 是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门科学，统计学习也称为统计机器学习。

统计学习的特点：

1. 统计学习以计算机及网络为平台，是建立在计算机及网络上的；
1. 统计学习以数据为研究对象，是数据驱动的学科；
1. 统计学习的目的是对数据进行预测与分析；
1. 统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析；
1. 统计学习是概率论、统计学、信息论、计算理论、最优化及计算机等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论。

`学习`：如果一个系统能够通过执行某个过程改进它的性能，这就是学习。

### 统计学习的对象

统计学习的对象是 `数据`。它从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。机器学习中最重要的概念就是特征，而特征是最后需要输入到模型中进行训练的多维数据向量，它是来自于各种不同类型的数据(如数字、文本、图像、音频、视频等)转换，这个转换的过程就是机器学习与数据挖掘领域很重要的一个步骤:“特征工程”。

统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这是统计学习的前提。在统计学习过程中，以变量或变量组表示数据。数据分为由连续变量和离散变量表示的形式。

### 统计学习的目的

统计学习用于对数据进行预测与分析，特别是对未知新数据进行预测与分析。

对数据的预测与分析是通过构建概率统计模型实现的。统计学习总的目的就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同样也要考虑尽可能地提高学习效率。

### 统计学习的方法

监督学习，非监督学习，半监督学习，强化学习等组成。

从给定的、有限的、用于学习的训练数据集合出发，假设数据是 **独立同分布** 产生的；并且假设要学习的模型属于某个函数的集合，称为 `假设空间`；应用某个评价准则，从假设空间中选取一个最优的模型，使它对已知训练数据及未测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现。这样，统计学习方法包括模型的假设空间、模型选择的准则以及模型学习的算法，统称其统计学习方法的三要素：简称为`模型`、`策略` 和 `算法`。

步骤如下：

1. 得到一个有限的训练数据集合；
1. 确定包含所有可能的模型的假设空间，即学习模型的集合；
1. 确定模型选择的准则，即学习的策略；
1. 实现求解最优模型的算法，即学习的算法；
1. 通过学习方法选择最优模型；
1. 通过学习的最优模型对新数据进行预测和分析。

### 统计学习的研究

研究分为方法、理论和应用。

### 统计学习的重要性

1. 统计学习是处理海量数据的有效方法。
1. 统计学习是计算机智能化的有效手段。
1. 统计学习是计算机科学发展的一个重要组成部分（属于系统、计算和信息三者中的信息）。

## 监督学习

监督学习的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出作出一个好的预测。

### 基本概念

### 问题的形式化

![监督学习问题](http://ofqm89vhw.bkt.clouddn.com/5fd67cd6d0cfb01f7980c031cdce0e02.png)

## 统计学习三要素

- `模型`：在监督学习过程中，模型就是所要学习的条件概率或者决策函数。
- `策略`：使用一种什么样的评价，度量模型训练过程中的学习好坏的方法，同时根据这个方法去实施的调整模型的参数，以期望训练的模型将来对未知的数据具有最好的预测准确度。
- `算法`：模型的具体计算方法。它基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后考虑用什么样的计算方法去求解这个最优模型。

损失函数和风险函数

损失函数(loss function)或代价函数(cost function)是用来度量模型的预测能力的。损失函数是 ${f(X)}$（预测值）和 ${Y}$（真实值）之间的非负实值函数（因为两者之间的差值可以理解为两者之间的距离，是非负的），记作 ${L(Y, f (X))}$。

当然还存在其他的损失函数比如：指数损失函数或者Hinge Loss等。损失函数值越小，代表模型越好，模型出现的误差越小。
经验损失或者经验风险
由于模型的输入、输出 ${(X,Y)}$ 是随机变量，遵循联合分布 ${P(X,Y)}$ ，所以损失函数的期望是：

这是理论上模型 ${f(X)}$ 关于联合分布 ${P(X,Y)}$ 的平均意义下的损失，称为风险函数(risk function)或期望损失(expected loss)。学习的日标就是选择期望风险最小的模型。由于，一方面根据期望风险最小化模型要用到联合概率分布，另一方面联合分布又是未知的，所以监督学习就成为一个病态问题！

在此我们提出另外一个概念：经验风险。(根据我自己的理解，带有“经验”的东东，一般是平均意义下东东，毕竟经验是需要积累的嘛。)
模型f(x)关于训练数据集的平均损失称为经验风险(empirical risk)或经验损失(empirical loss):

期望风险 ${R_{exp}(f)}$ 是模型关于联合分布的期望损失，经验风险 ${R_{emp}(f)}$ 是模型关于训练样本集的平均损失。根据大数定律，当样本容量 ${N}$ 趋于无穷时，经验风险趋于期望风险。所以一个很自然的想法是用经验风险估计期望风险。但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常并不理想，要对经验风险进行一定的矫正.这就关系到监督学习的两个基本策略:经验风险最小化和结构风险最小化.

经验风险最小化(empirical risk minimization, ERM)，即求解最优化问题：

### 算法

学习模型的具体计算方法。统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法。如何找到全局最优解并使得求解的过程非常高效！

## 模型评估和模型选择

### 训练误差与测试误差

### 过拟合与模型选择

过拟合(over-fitting)：如果一味追求提高对训练数据的预侧能力，所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合(over-fitting)。过拟合是指学习时选择的模型对己知数据（训练数据集中的数据）预测得很好，但对未知数据（测试数据集中的数据）预测得很差的现象。

![训练误差和测试误差与模型复杂度的关系](http://ofqm89vhw.bkt.clouddn.com/2e0def1e5c6306e2d582cbb6785efd22.png)

## 正则化与交叉验证

### 正则化

### 交叉验证

`简单交叉验证`：首先随机地将己给数据分为两部分，一部分作为训练集，另一部分作为测试集；然后用训练集在各种条件下(例如，不同的参数个数)训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型.

`k-折交叉验证`(S-fold cross validation）：首先随机地将已给数据切分为 ${S}$ 个互不相交的大小相同的子集；然后利用 ${S-1}$ 个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的 ${S}$ 种选择重复进行；最后选出 ${S}$ 次评测中平均侧试误差最小的模型.

`留一文叉验证` (leave-one-out cross validation)：${k}$-折交叉验证的特殊情形是 ${k=N}$，${N}$ 是给定数据集的容量。

## 泛化能力

### 泛化误差

### 泛化误差上街

## 生成模型与判别模型

监督学习方法又可以分为生成方法(generative approach)和判别方法(discriminative approach)。所学到的模型分别称为生成模型(geuemtive model)和判别模型(discriminative model)。生成方法由数据学习联合概率分布 ${P(X,Y)}$ ，然后求出条件概率分布 ${P(Y|X)}$ 作为预测的模型，即生成模型。

这样的方法之所以称为生成方法，是因为模型表示了给定输入X产生输出Y的生成关系.典型的生成模型有:朴素贝叶斯法和隐马尔可夫模型。

判别方法由数据直接学习决策函数 ${f(X)}$ 或者条件概率分布 ${P(Y|X)}$ 作为预测的模型，即判别模型.判别方法关心的是对给定的输入 ${X}$ ，应该预测什么样的输出 ${Y}$ 。典型的判别模型包括k近邻法、感知机、决策树、逻辑斯谛回归模型、最大嫡模型、支持向量机、提升方法和条件随机场等。

给定输入 ${X}$ ,生成模型不能直接预测出输出的 ${y}$ ，需要计算之后，再比较（或者求出的是各种输出可能性的概率值，最大作为最终的求解结果），而判别模型可以直接给出预测结果 ${y}$ ,（利用判断规则或者方法）。

生成方法的特点：

1. 生成方法可以还原出联合概率分布 ${P(X,Y)}$ ，而判别方法则不能；
1. 生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；
1. 当存在隐变量时，仍可以用生成方法学习，此时判别方法就不能用。

判别方法的特点：

1. 直接学习的是条件概率 ${P(Y|X)}$ 或决策函数 ${f(X)}$ ，直接面对预测，往往学习的准确率更高；
1. 由于直接学习 ${P(Y|X)}$ 或 ${f(X)}$ ，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题.

## 分类问题

![分类问题](http://ofqm89vhw.bkt.clouddn.com/ee33a8fa597650465fda1fbc143ad28d.png)

- TP(True Positive)——将正类预测为正类数(d);
- FN(False Negative)——将正类预测为负类数(c);
- FP(False Positive)——将负类预测为正类数(b):
- TN(True Negative)——将负类预测为负类数(a).

精确率： ${P(Positive)=\frac{TP}{TP+FP}=\frac{d}{d+b}}$

召回率： ${P(Positive)=\frac{TP}{TP+FN}= \frac{d}{d+c)}}$

${F1}$（精确率和召回率的调和均值）： ${F1(Positive)= \frac{2*P*R}{P+R}}$

同理可以求得 ${P(Negative)}$ 、 ${R(Negative)}$ 、 ${F1(Negative)}$

这三种度量一般用于检测模型对每一类别的检测或预测能力。

对模型整体评估如有准确率 ${AC(accuracy)}$，${AC= \frac{a+d}{a+b+c+d}}$ (对角线元素，正类和负类都预测正确的样本数)/(样本总数)
还有 ${ROC}$ 曲线等。

## 标注问题

![标注问题](http://ofqm89vhw.bkt.clouddn.com/6e28bb00f69b511748c80b6b36c2ac9f.png)

## 回归问题

![回归问题](http://ofqm89vhw.bkt.clouddn.com/0f48650bb9c87b8c825ff6eb3faa69fc.png)

## 本章概要

## 继续阅读

## 习题

## 参考文献
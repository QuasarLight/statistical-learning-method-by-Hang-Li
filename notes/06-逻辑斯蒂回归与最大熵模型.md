# 逻辑斯谛回归与最大熵模型

> 逻辑斯谛回归与最大熵模型都属于对数线性模型。

## 逻辑斯谛回归模型

### 逻辑斯谛分布

![逻辑斯谛分布的魔都函数与分布函数](http://ofqm89vhw.bkt.clouddn.com/703eccd4a4d3296e129db467ca6a80c6.png)

### 模型的参数估计

### 多项逻辑斯谛回归

> 二元的逻辑斯谛回归模型用于二分类，可以将其推广为多元逻辑斯谛回归模型，用于多分类。

假设离散型随机变量 ${Y}$ 取值集合是 ${1, 2, ..., K}$，那么多项逻辑斯谛回归模型是：

$${P(Y = K|x) = \frac{exp(w_k, x)}{ 1 + \sum_{k=1}^{K-1}exp(w_k, x)}\ \  , k = 1, 2, \cdots, K-1}$$

$${P(Y = K|x) = \frac{1}{1 + \sum_{k=1}^{K-1}exp(w_x · x)}}$$

这里，${x \in R^{n+1},\ w_k \in R^{n+1}.}$

同理，二元的逻辑斯谛回归的参数估计也可以将其推广为多元逻辑斯谛回归。

## 最大熵模型

### 最大熵原理

学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵模型也可以表示在满足约束条件的模型集合中选取熵最大的模型。

假设离散型随机变量 ${X}$ 的概率分布是 ${P(X)}$，则其熵为：

$${H(P) = - \sum_{x} P(x) · \log P(x)}$$

熵满足下列不等式：

$${0 \leq H(P) \leq \log|X|}$$

在上式中，${|X|}$ 是 ${X}$ 的取值个数，当且仅当 ${X}$ 的分布式均匀分布的式，右边的等号成立，即当 ${X}$ 是均匀分布的时候，熵最大。

较为直观的说法，最大熵原理认为，要选择的概率模型首先必须满足已有的事实，即 `约束条件`，在没有更多的信息的情况下，那么不确定的部分都是 `等可能的`。最大熵原理通过 `熵` 的最大化来表示等可能性，`熵` 其实描述的是系统的混乱程度的，`等可能` 其实是混乱程度最大的情况，而熵是一个在数值上可以优化的指标。

### 最大熵模型的定义

学习的目标是用最大熵原理选择最好的分类模型。

假设分类模型是一个条件概率分布 ${P(Y|X)}$，${X}$

![最大熵模型的定义](http://ofqm89vhw.bkt.clouddn.com/f8e9c1cdab1577ed57720f979fc6170f.png)

`模型`：假设满足所有约束条件的模型集合为 ${C = {}}$, 定义在条件概率上 ${P(Y|X)}$ 上的条件熵为 ${H(P) = - \sum_{x ,y} P(x) P(y|x) \log^{P(y|x)}}$，则模型集合 ${C}$ 中条件熵 ${H(P)}$ 最大的模型称为最大熵模型，其中，对数为自然对数。

### 最大熵模型的学习

最大熵模型的学习过程就是求解最大熵模型的过程，最大熵模型的学习可以形式化为最优化的问题。

![](http://ofqm89vhw.bkt.clouddn.com/2c9c1ffd7cd05a23ee6051f142254d21.png)

## 模型学习的最优化算法

### 改进的迭代尺度法


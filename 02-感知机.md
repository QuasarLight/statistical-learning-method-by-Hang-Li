# 感知机

这是一个线性的模型，意在用一条线（超平面）对训练数据进行二分。

输入：训练数据的特征向量
输出：二值类标
前提是数据严格线性可分，即存在一条线（超平面）能将正负例完美分开。而学习的目的即为学出这个分离线（超平面）。
学习的策略为经验风险最小化，即误分类点数最少，而假设是线性可分，因此误分类点数一定可以降为0。但是，误分类点数并不能指导我们如何修改模型（不能导出有效的算法），因此我们修改了一下策略的表示，改为误分类点到分离平面的距离之和。因此损失函数为：

$$
L(w, b) = -\sum\limits_{x_i\in M} y_i(w_i+b) 
$$

其中，(M)为误分类点集，(w)和(b)为参数，(y_i)是标准类标，乘上(y_i)乘积保证为正。为求其极小，分别对参数求导并令其导数为0即可

$$
<!-- \begin{align} -->
<!-- \notag  -->
&\nabla_w L(w, b) = -\sum\limits_{x_i\in M}y_ix_i \\ 
$$

$$
&\nabla_b L(w, b) = -\sum\limits_{x_i\in M}y_i 
<!-- \end{align} -->
$$

学习算法为梯度下降法，有原始形式和对偶形式之分。
原始形式核心递归式：